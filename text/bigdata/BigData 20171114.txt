빅데이터

데이터 수집- 절차

수집절차를 설계하고, 충분한 테스트를 걸쳐 수집 진행해야 함

데이터 수집 >> 서비스 품질좌우
○ 데이터 수집 절차중, 심각한 문제 발생 >> 프로젝트 전체 재설계 경우도 발생
○ 데이터 수집계획수립위해 >> 데이터 수집 관여 프로젝트 특성 파악 필요
○ 데이터 수집 프로젝트의 특성
  일반업무 프로젝트
      데이터의 확보가 프로젝트의 품질과 성패를 좌우하지 않음
      오히려, 데이터확보보다, 데이터의 관리 측면에 더 집중
  데이터 수집 절차가 포함된 프로젝트
      데이터의 확보가 프로젝트의 품질과 성패를 결정하는 경우가 대부분

데이터 수집이 프로젝트에 미치는 영향 >> 프로세스 비교로 차이점 비교

1. 데이터 입력

일반 프로젝트     데이터발생 >> 사용자,데이터오너쉽 >> 데이터 입력자
                 트랜잭션 하나당 >> 한건 씩 데이터 발생

수집관련 프로젝트  데이터 발생 >> 수집프로세스자체, 수집정책관련 기술에 대한 데이터 오너쉽 존재, 프로세스 하나당 >> 데이터 여러 건 발생

--------------------------------------------------------------------------------------------------------------------------------

데이터수집이 프로젝트에 미치는 영향 >> 프로세스 정의로 차이점 비교

2. 데이터 처리

일반 프로젝트       입력데이터의 사전 및 사후 처리 과정이 거의 미존재
                   원본 데이터 변경이 없음
수집관련 프로젝트   대부분 데이터 전처리 과정이 필요
                   수집 데이터의 후처리(다른 데이터와의 병합)가 이뤄짐

3. 서비스 제공

일반 프로젝트     변형없이 처리 데이터 제공 >> 데이터의 생상과 출력이 일치,
                  OLTP 기반 프로젝트가 주를 이룸
수집관련 프로젝트  처리된 데이터를 분리/병합 >> 새로운 인사이트 제공 서비스가 주.
                  재생산 과정을 거쳐 생선된 데이터가 출력. 데이터 분석 프로젝트가 주를 이룸

--------------------------------------------------------------------------------------------------------------------------------

데이터 수집이 프로젝트에 미치는 영향 >> 프로세스 내용으로 차이점 비교로


데이터 입력 >>> 데이터 처리

일반 프로젝트        입력받은 대로, 데이터 처리진행, 데이터 처리시, 정규화가 중요한 요소
수집관련 프로젝트    데이터 수집과 처리 >> 누락 데이터에 대한 사전처리 작업 필요, 데이터 처리시 , 수집데이터의 가공이 발생

데이터 처리 >>> 서비스 제공

일반 프로젝트        처리된 데이터와 원본 데이터가 정규성을 가짐 >> 서비스 제공에서도, 처리된 데이터와 제공 서비스 항목이 데이터조회 형태로만 제공됨
수집관련 프로젝트     제공서비스 대부분이 분석과 관련 >> 데이터 처리는 원본 데이터의 변환이 발생, 서비스 제공형태에 따라 처리방법 수정 발생 가능


데이터 입력 >>> 서비스 제공

일반 프로젝트       입력테이터와 서비스에 제공 데이터 >> 가역적 선형관계 , 서비스제공 데이터로부터,
                   입력데이터로 역 추적 가능, 데이터 입력중단돼도, 서비스 제공가능
수집관련 프로젝트    서비스에 제공된 데이터, 수집 데이터의 내부 처리과정 거쳐 서비스 목적에 맞춰 변형(재생산) 된 새로운 데이터, 
                   서비스 제공과 수집은 하나의 업무처리 선상 >> 서비스 제공은 데이터 수집에 영향을 받음

--------------------------------------------------------------------------------------------------------------------------------

○ 데이터 수집절차 세계

1. 데이터 선정

  - 프로젝트 품질 결정
  - 프로젝트의 성공 여부, 진행여부에 영향을 미치는 핵심업무
  - 수집대상 데이터의 분석가능한 업무지식, 수집노하우 보유 전문가가 수행
  - 목적론적 데이터 특성을 이해한 일반 사람들도 경험을 통해 진행가능
  - 최우선 고려사항
  
  1. 수집 가능성 >> 데이터 선정시, 가장 우선적인 고려사항
      - 수집불가능 or 통제불가능 주기의 데이터 >> 서비스 활용용이, 원천 데이터의 정책에 의존
      - 수집 용이하더라도 서비스 활용측면에서, 데이터 전후 처리 비용이 높으면 좋은 데이터 선정이라 할수 없음
 
  2.활용데이터의 보안 문제
      - 수집 데이터가, 개인정보보호 or 저작권 문제 없는지 확인
      - 관련 문제 발생 시, 서비스 활용에 심각한 문제 발생 >> 반드시 확인해야 함
  
  3. 데이터의 정확성
      - 서비스 활용목적에 세부항목이 정확히 존재하는지 검토
      - 수집목적에 맞는 데이터 수집위해 >> 사전처리 과정필요
      - 사전처리 방안도 준비 필요
  
  4. 수집 난이도
      - 데이터 수집 처리 소요비용이 높은 경우 >> 대안고려
      - 데이터 분석 설계와 필요 데이터를 얻기 위해,
        많은 정제과정이 필요한 경우도 >> 대안 고려
      - 직접 비용산출이 어려운 정성적인 경우 >> 수집 난이도 측면에서,
        트래픽 량과 저장 처리 장치 용량 등이 고려 대상 >> 수집대상의 대안 고려사항
  
  5. 수집비용
      - 데이터 획득위해, 직접적으로 들어가는 획득비용
      - 정략적 기준으로, 수집기술 비용이 발생할 경우 >> 수집 기술 검토 필요


2. 수집 세부계획 수립 (데이터 선정후)
      1. 선정된 데이터의 위치파악
      2. 데이터 유형 파악
      3. 수집기술과 보안사항 등 점검
      4. 수집계획서 작성

    세부절차
      1. 수집데이터의 위치 파악
        - 내부 혹은 외부에 있으냐에 따라, 소유기관과의 협의 필요
        - 저장 위치 별, 데이터 유형
          (a) 내부
               내부시스템과의 연계가능성 파악
               데이터 종류와 수집주기, 인터페이스 정의서 작성
          (b) 외부 
               OpenAPI 개방 데이터 종류와 형태 파악, 데이터 량과 트래픽 정도 확인
               연계방식 및 절차, 수집기술 적용방안 검토
               크롤링(crawling) 방식 적용시, 외부 시스템 생명주기 및 저작권 문제 등,
               수집가능여부확인, 수집기술 적용방안 검토, 서비스 종료시의 대안, 소스검토
      
      2. 데이터 유형 파악 및 수집 방법 적용
        - 데이터 수집기술을 경정하는 중요한 과정
        - 수집 데이터 형태를 파악해, 데이터 유형을 나눠보고,
          어떤 수집 방법이 사용되는지 확인 필요
          (a) 구성형태별 데이터 유형
              형태   존재형태      특징
              정형   RDB,FILE     데이터 스키마 지원
              반정형 FILE         데이터 내에, 메타 속성 존재
              비정형 RDB, FILE    분석가능 텍스트 파일, 이미지/동양상 파일로 존재
          (b) 존재 형태별 데이터 유형
              형태   존재형태      특징
              RDB   정형,비정형    DBtoDB, ETL(Extract Transformation Loading), RDB 벤더 제공 드라이버
              FILE  반정형         FTP,HTTP,crawling,OpenAPI
      3. 수집 계획서 작성
        - 데이터 수집 설계를 위해, 수집 계획서 작성
        - 수집 계획서 >> 데이터 소스, 수집주기, 수집방법 등이 구체화 되어야 함
          
          (a) 데이터 소스 (구성요소)

          항목          작성내용                                                                     고려사항
          소스위치      내부시스템:특정 RDB의 IP/PORT 등이 포함될수 있음                               여러소스존재시, 중요소스 별로 모두 기술
                       외부시스템:URI 등 기술
          데이터 유형   물리적으로 존재하는 데이터 유형을 파일종류, RDB일 경우는 DBMS 종류 등을 기술      혼합 데이터 유형의 경우, 의존관계 기술
          인터페이스    수집항목의 세부내용에 대해 인터페이스 요소 기술
          데이터 담당자 소스데이터 담당자와 연락처 기술, 
                       담당자를 알지 못하는 경우, 기관명 or 대표 URL만 기술 사능
          협약 내용     데이터 원천 담당자와의 협약 내용 기술
                       협약사항은 별도 첨부 문서로 관리가능                                            법적검토
        
          (b) 수집주기(구성요소)

          주기설정

          (c) 수집방법

          적용기술
          데이터 사전처리
          데잍 사후처리
          대안 기술

3. 테스트 수집 진행

  - 수집계획서 완성 후, 테스트 수집 진행
  - 수집 관련 프로젝트에서, 단순히 수집기능 테스트만 진행하는 것이 아님
  - 즉, 데이터 선정 시 고려 했던, 데이터 수집가능성/ 보안문제/ 정확성 여부 검증해 보고, 데이터의 서비스 활용 측면까지 검토해보아야함

    1. 수집테스트의 기술적 검토
      - 데이터의 정확한 수집여부, 적용된 기술적 방법의 최적여부 등 검토
      검토항목            작성내용
      데이터세트누락       원본데이터 요청후 확인
                          재 수집 통해, 누락 데이터 세트확인
      소스데이터와 비교    파일일 경우, 사이즈 비교
                          수집 데이터와 개수 비교
      데이터의 정확성      서비스 활용에 수집한 데이터의 사후처리가 필요한 지 확인

    2. 수집 테스트의 업무적 검토
      - 수집 데이터에 대한 개인정보보안, 저작권 관련 사항 등 업무적 검토
      - 협약기관에 많은 트래픽 발생시킬 경우, 제약사항 등 재 검토 필요

--------------------------------------------------------------------------------------------------------------------------------

kshf59@Bit:/mnt/c/Users/Bitcamp/Downloads$
------------------------------------------------------------------------------------------------------------
kshf59@Bit:/mnt/c/Users/Bitcamp/Downloads$ scp apache-flume-1.8.0-bin.tar.gz hadoop@hadoop-master:/opt/.   |
위에 방법 아니면 밑에 방법으로 리눅스에 넣는다                                                                 |
kshf59@Bit:/mnt/c/Users/Bitcamp/Downloads$ sftp hadoop@hadoop-master                                       |
sftp> put apache-flume-1.8.0-bin.tar.gz /opt/apache-flume-1.8.0-bin.tar.gz                  |
------------------------------------------------------------------------------------------------------------
위의 방법보다는 사이트에서 링크 복사를 해서 바로 다운로드 하는걸 추천한다.

[hadoop@hadoop-master /opt](9)# wget http://www.apache.org/dist/flume/stable/apache-flume-1.8.0-bin.tar.gz

$ gzip -d apache-flume-1.8.0-bin.tar.gz  압축을 해재하는것  -d 는 해재 하라는 명령어
$ gzip apache-flume-1.8.0-bin.tar        압축을 gzip으로 하라는 것
$ tar tvf apache-flume-1.8.0-bin.tar     폴더의 구조를 보는것  gzip 이 아니라서 tvf 에서 z 뺌
$ tar xvf apache-flume-1.8.0-bin.tar     tar 압축 풀기

$ ln -s /opt/apache-flume-1.8.0-bin /opt/flume
    -->>  flume의 소프트링크를 걸어주거라

[hadoop@hadoop-master /opt](26)# ll
total 12
drwxrwxr-x.  7 hadoop hadoop  187 Nov 14 11:42 apache-flume-1.8.0-bin
lrwxrwxrwx.  1 hadoop hadoop   27 Nov 14 11:49 flume -> /opt/apache-flume-1.8.0-bin
lrwxrwxrwx.  1 hadoop hadoop   17 Nov 13 15:01 hadoop -> /opt/hadoop-1.2.1
drwxr-xr-x. 16 hadoop hadoop 4096 Nov 11 22:40 hadoop-1.2.1
drwxr-xr-x. 11 hadoop hadoop  173 Nov 12 09:01 hadoop-2.8.2
lrwxrwxrwx.  1 root   root     17 Nov  5 14:04 java -> /opt/jdk1.8.0_152
drwxr-xr-x.  8 root   root    255 Sep 14 18:27 jdk1.8.0_152
-rwxrw-r--.  1 hadoop hadoop   51 Nov 13 15:03 mvHadoop1to2.sh
-rwxrw-r--.  1 hadoop hadoop   51 Nov 12 14:34 mvHadoop2to1.sh

$ ssh hadoop-secmaster
$ wget http://www.apache.org/dist/flume/stable/apache-flume-1.8.0-bin.tar.gz
$ ln -s /opt/apache-flume-1.8.0-bin /opt/flume

$ sudo su -root
# cd /etc/profile.dist
# touch flume.sh
# vi flume.sh
      1 export FLUME_HOME=/opt/flume
      2 export FLUME_CONF_DIR=${FLUME_HOME}/conf
      3 export PATH=${FLUME_HOME}/bin:${PATH}
# source /etc/profile

[root@hadoop-secmaster /etc/profile.d](5)# env | grep FLUME
FLUME_CONF_DIR=/opt/flume/conf
FLUME_HOME=/opt/flume
[root@hadoop-secmaster /etc/profile.d](6)# echo $PATH
.:/opt/java/bin:/opt/hadoop/bin:/opt/flume/bin:.:/opt/java/bin:/opt/hadoop/bin:
.:/opt/java/bin:/opt/hadoop/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/hadoop/.local/bin:/home/hadoop/bin

# scp flume.sh root@hadoop-master:/etc/profile.d/.
    --> root 권한이기 때문에 root@ 로 한다
# ssh hadoop-master
# env | grep FLUME
    FLUME_CONF_DIR=/opt/flume/conf
    FLUME_HOME=/opt/flume
# echo $PATH

$ su hadoop
$ cd /opt/flume/conf/
$ mkdir template
$ mv *.template template
      --> 모든 template 파일을 새로만든 template 폴더에 옮긴다.
$ cd template
$ cp flume-env.sh.template ../flume-env.sh
$ cp flume-conf.properties.template flume-conf.properties ../
$ cd /opt/flume/conf/
$ vi flume-env.sh
      --> export JAVA_HOME=${JAVA_HOME} 추가
   
$ ssh hadoop-secmaster
$ cd /opt/flume/conf/
$ mkdir template
$ mv *.template template
      --> 모든 template 파일을 새로만든 template 폴더에 옮긴다.
$ cd template
$ cp flume-env.sh.template ../flume-env.sh
$ cp flume-conf.properties.template flume-conf.properties ../
$ cd /opt/flume/conf/
$ vi flume-env.sh
      --> export JAVA_HOME=${JAVA_HOME} 추가
$ ssh hadoop-master
$ flume-ng \
  agent \
  --conf-file /opt/flume/conf/flume-conf.properties \
  --name agent -Dflume.root.logger=INFO,console
$ mv flume-conf.properties flume-conf.properties.seq
$ touch flume-conf.properties

$ vi flume-conf.properties
  2 netcat.sources = s1
  3 netcat.channels = c1
  4 netcat.sinks = k1
  5
  6
  7 netcat.sources.s1.type = netcat
  8 netcat.sources.s1.bind = 0.0.0.0
  9 netcat.sources.s1.port = 44444
 10 netcat.sources.s1.channels =  c1
 11
 12
 13 netcat.channels.c1.type = memory
 14 netcat.channels.c1.capacity = 100
 15
 16
 17 netcat.sinks.k1.type = logger
 18 netcat.sinks.k1.channel = c1

$  # flume-ng \
   agent \
   --name netcat \
   --conf-file /opt/flume/conf/flume-conf.properties \
   -Dflume.root.logger=INFO,console
$ netstat -nlt
$ sudo firewall-cmd --permanent --zone=public --add-port=44444/tcp
    --> 방화벽 열기
$ sudo firewall-cmd --reload
$ sudo firewall-cmd --list-ports
9000/tcp 50070/tcp 50090/tcp 50075/tcp 50020/tcp 50010/tcp 9001/tcp 50030/tcp 50060/tcp 39079/tcp 8020/tcp 8030/tcp 8031/tcp 8032/tcp 8088/tcp 50080/tcp 44444/tcp

$  # flume-ng \
   agent \
   --name netcat \
   --conf-file /opt/flume/conf/flume-conf.properties \
   -Dflume.root.logger=INFO,console

  * test *
  1) open new terminal
  2) ssh hadoop-secmaster ( NOT hadoop-master )
  3) # telnet hadoop-master 44444
Trying 192.168.252.131...
Connected to hadoop-master.
Escape character is '^]'.
Hello!!! Flume !
OK


hadoop-master 접속

$ vi flume-conf.properties
:1,$s/netcat/tail/g
    --> netcat 단어를 tail 로 바꿔주세요 (g)글로벌

  2 tail.sources = s1
  3 tail.channels = c1
  4 tail.sinks = k1
  5
  6
  7 tail.sources.s1.type = exec
  8 tail.sources.s1.command = tail -f /var/log/secure
  9 tail.sources.s1.channels =  c1
 10
 11
 12 tail.channels.c1.type = memory
 13 tail.channels.c1.capacity = 100
 14
 15
 16 tail.sinks.k1.type = logger
 17 tail.sinks.k1.channel = c1

$ flume-ng agent --name tail --conf-file /opt/flume/conf/flume-conf.properties -Dflume.root.logger=INFO,console

* test *
1) open new terminal
2) ssh hadoop-master
   $ cd /var/log
3) # sudo tail -40f secure
    --> 40f 는 40줄 기본 default 값은 10줄
4) open new terminal
5) ssh hadoop-master
6) check flume console
  --->  ssh 접근의 로그가 secure 에서 찍힌다



 /opt/flume/conf/flume-conf.properties, Create Workflow #4 - Multi-agent

   1) on hadoop-master

  1 hadoop-master.sources = s1
  2 hadoop-master.channels = c1
  3 hadoop-master.sinks = k1
  4
  5
  6 hadoop-master.sources.s1.type = exec
  7 hadoop-master.sources.s1.command = sudo tail -f /var/log/secure
  8 hadoop-master.sources.s1.channels =  c1
  9
 10 hadoop-master.channels.c1.type = memory
 11 hadoop-master.channels.c1.capacity = 100
 12
 13 hadoop-master.sinks.k1.type = avro
 14 hadoop-master.sinks.k1.hostname = hadoop-secmaster
 15 hadoop-master.sinks.k1.port = 10000
 16 hadoop-master.sinks.k1.channel = c1
 17

  2) on hadoop-secmaster

  1 hadoop-secmaster.sources = s1
  2 hadoop-secmaster.channels = c1
  3 hadoop-secmaster.sinks = k1
  4
  5
  6 hadoop-secmaster.sources.s1.type = avro
  7 hadoop-secmaster.sources.s1.bind = 0.0.0.0
  8 hadoop-secmaster.sources.s1.port = 10000
  9 hadoop-secmaster.sources.s1.channels =  c1
 10
 11 hadoop-secmaster.channels.c1.type = memory
 12 hadoop-secmaster.channels.c1.capacity = 100
 13
 14 hadoop-secmaster.sinks.k1.type = logger
 15 hadoop-secmaster.sinks.k1.channel = c1


  * firewall open *
  # sudo firewall-cmd --permanent --zone=public --add-port=10000/tcp
	success
  # sudo firewall-cmd --reload
	success

  # sudo firewall-cmd --list-ports
   ... 10000/tcp


  * 실행1 - hadoop-secmaster *

  # flume-ng agent --name hadoop-secmaster --conf-file /opt/flume/conf/flume-conf.properties -Dflume.root.logger=INFO,console

17/11/14 04:54:15 INFO node.Application: Starting Source s1
17/11/14 04:54:15 INFO source.AvroSource: Starting Avro source s1: { bindAddress: 0.0.0.0, port: 10000 }...
17/11/14 04:54:15 INFO instrumentation.MonitoredCounterGroup: Monitored counter group for type: SOURCE, name: s1: Successfully registered new MBean.
17/11/14 04:54:15 INFO instrumentation.MonitoredCounterGroup: Component type: SOURCE, name: s1 started
17/11/14 04:54:15 INFO source.AvroSource: Avro source s1 started.


  * open new terminal on hadoop-secmaster
  # netstat -nlt
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State
tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN
tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN
tcp6       0      0 :::111                  :::*                    LISTEN
tcp6       0      0 :::10000                :::*                    LISTEN
tcp6       0      0 :::39281                :::*                    LISTEN
tcp6       0      0 :::22                   :::*                    LISTEN
tcp6       0      0 ::1:25                  :::*                    LISTEN
tcp6       0      0 :::50090                :::*                    LISTEN


  * 실행2 - hadoop-master *

  # flume-ng agent --name hadoop-master --conf-file /opt/flume/conf/flume-conf.properties -Dflume.root.logger=INFO,console

17/11/14 04:54:47 INFO source.ExecSource: Exec source starting with command: sudo tail -f /var/log/secure
17/11/14 04:54:47 INFO sink.AbstractRpcSink: Rpc sink k1: Building RpcClient with hostname: hadoop-secmaster, port: 10000
17/11/14 04:54:47 INFO sink.AvroSink: Attempting to create Avro Rpc client.
17/11/14 04:54:47 INFO instrumentation.MonitoredCounterGroup: Monitored counter group for type: SOURCE, name: s1: Successfully registered new MBean.
17/11/14 04:54:47 INFO instrumentation.MonitoredCounterGroup: Component type: SOURCE, name: s1 started
17/11/14 04:54:47 WARN api.NettyAvroRpcClient: Using default maxIOWorkers
17/11/14 04:54:47 INFO sink.AbstractRpcSink: Rpc sink k1 started.


  * tcp network session *

  # netstat -nat | grep .10000
tcp6       0      0 :::10000                :::*                    LISTEN
tcp6       0      0 192.168.252.130:10000   192.168.252.131:59718   ESTABLISHED


  * test *

  # sudo echo "<33> hello via syslog" | nc -t localhost 5140 //안됨
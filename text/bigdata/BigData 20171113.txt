빅데이터


반정형(semi-structured) 데이터

1. 특징
정형데이터 : 데이터 스키마 정보관리(RDBMS) + 데이터 내용 저장소(DB)로 구분
데이터 내부에 , 정형 데이터의 스키마에 해당하는 메타데이터를 가짐
일반적으로 파일 형태로 저장

2. 탐색

데이터내부에 , 데이터 구조에 대한 메타데이터 를 가짐어떤 형태를 가진 데이터 인지를 파악하는것이 필요
데이터 내부의 규칙성을 파악 >>>> 데이터 파싱(pasing) 규칙 적용

3. 예

HTML,XML,JSON
Web Log
LOT Sensor's sensing data

--------------------------------------------------------------------------------------------------------------------------------

비정형(unstructured) 데이터

1. 특징

데이터 셋(dataset)이 아닌, 하나의 데이터가 수집 데이터로 객체화
대표적인 데이터
  - 언어분석 가능한 텍스트 데이터
  - 이미지, 동영상같은 멀티미디어 데이터
웹 페이지의 경우
  - HTML 형태로 존재 >> 반정형 데이터로 구분할 수 도 있음
  - 텍스트 마이닝을 통해 수집하는 경우도 존재 >> 명확한 구분이 어려움

2. 탐색

이진파일형태 : 동영상 이미지
스크립트(script) 파일 형태 : 소셜 데이터의 텍스트
이진 파일 형태의 데이터인 경우 >> 데이터 종류별로 응용 sw를 이용하여 탐색
스크립트 형태의 데이터인 경우 >> 데이터를 파싱해 처리

--------------------------------------------------------------------------------------------------------------------------------

데이터 수집-분류

수집데이터의 형태와 데이터 수집과의 관계

데이터 수집이 가능할 경우, 아래 세가지 측면으로 비교하면,

1. 수집의 난이도
데이터 난이도 특징
정형   하    대부분 내부 데이터, 수집 쉬움
반정형 중    보통 API 형태로 제공, 데이터 처리기술 요구
비정형 상    텍스트 마이닝, 파일의 경우는 파싱 필요 >> 처리 어려움

2. 데이터 처리 아키텍처 구성

데이터 처리 아키텍처 구성
데이터 난이도 특징
정형   하    보통,CRUD 아키텍처 구조
반정형 중    메타데이터 구조 해석 >>> 정형 데이터로 변환 아키텍처 구성
비정형 상    텍스트 or 파일 파싱 >> 반정형 >> 정형 변환 아키텍처 구성

3. 데이터의 잠재적가치
데이터 난이도   특징
정형   보통     내부 데이터 특성상, 현실적 가치 한계상, 상대적 
반정형 높음     제공자가 선별해 제공 >>> 정형 데이터보다 높음
비정형 매우높음 목적론적 데이터, 수집 주체에게 가장 높은 잠재 가치

--------------------------------------------------------------------------------------------------------------------------------

○ 수집데이터의 위치에 따른 분류

- 배치 처리시, 데이터 위치에 따른 구분
  1. 내부 데이터 :  동일한 내부의 시스템계에 저장되는 데이터
  2. 외부 데이터 : 외부 시스템에 저장된 데이터

- 실시간 처리에서는,
  수집데이터가 저장되는 위치가 아니라
  수집 데이터가 발생하는 위치에 따라 내부, 외부로 구분

- 내부/외부 구분 사유
  데이터의 위치에 따른, 원천 시스템과 연계를 위한
    1. 인터페이스의 기술적 방법과
    2. 정책적 차이점

내부 데이터

1. 특징
  - 수집 대상, 원천 데이터의 저장소가 내부 시스템계에 있는 데이터
  - 내/외부 데이터의 가장 큰 구분별점 >> 
    데이터 제공자와 상호 협약에 의한  의사소통의 가능여부
  - 상대적으로 적은 기술적제약 >> 원천/수집 데이터가 동일 시스템계에 저장

2. 인터페이스 방법
  - 대상데이터의 수집주기와 방법 >> 데이터 제공자와의 협약을 통해 결정
  - 수집실패 데이터의 재수집이 가능하도록 구현 가능 >> 수집성공여부에 따른 별도의 인터페이스 설정

외부 데이터

1. 특징
  - 수집대상 원천 데이터 저장소가 외부 시스템에 있는 데이터 
  - 내부 데이터와의 가장 큰 구별점 >> 데이터 제공자와 협약 된 관계가 아니면, 상호 의사소통 불가능
  - 데이터 수집위한, 수집주기 및 방법에 관한 분석 필요

2.인터페이스 방법
  - 수집항목을 분석해, 수집 시스템 설계
  - 미 협약 시스템의 경우, 수집 실패 시 대안 준비해야 함
  - 가능 한 데이터 전처리 과정 없이 원본 데이터 수집후, 수집 시스템에서 처리가능한 인터페이스 설계가 바람직함

--------------------------------------------------------------------------------------------------------------------------------

수집 데이터의 위치와 데이터 수집의 관계
수집 데이터의 위치와 데이터 수집과의 관계를, 아래 세가지 측면에서 분석

1. 수집 난이도
위치 난이도  특징
내부 하     데이터 저장소가 내부에 있음, 의사소통 원활
외부 상     소스 데이터담당자와 의사소통 어려움

2. 데이터 처리 아키텍처
위치 난이도  특징
내부 하      대부분 정형데이터, 일반적인 CRUD 처리 아키텍처 구성 가능
외부 상      대부분 비정형/반정형 데이터, 추가적인 아키텍쳐 구성 필요

3. 데이터의 잠재적 가치
위치 난이도  특징
내부 보통    내부 데이터 특성상, 현실적 가치의ㅔ 한계상 활용측면 낮음
외부 높음    목적론적 데이터, 수집 주체에게 가장 높은 잠재 가치

--------------------------------------------------------------------------------------------------------------------------------

#  ssh hadoop-이름 -C "/opt/mvHadoop1to2.sh"   하둡 2에서 1로 바꿔줌
#  ssh hadoop-이름 -C "/opt/mvHadoop2to1.sh"   하둡 2에서 1로 바꿔줌
  -->  "/opt.mvHadoop2to1" 이런 파일안에
          rm /opt/hadoop
          ln -s /opt/hadoop-2.8.2 /opt/hadoop
       이런 명령어가 들어있다. 
# htop
  --> 프로세스 확인하는 명령어

하둡2
# env | grep HADOOP
  HADOOP_HOME=/opt/hadoop
  HADOOP_PID_DIR=/opt/hadoop/pids
  HADOOP_PREFIX=/opt/hadoop
  HADOOP_HDFS_HOME=/opt/hadoop
  HADOOP_COMMON_HOME=/opt/hadoop
  HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
  HADOOP_MAPRED_HOME=/opt/hadoop

하둡1
# env | grep HADOOP
HADOOP_HOME=/opt/hadoop
HADOOP_PID_DIR=/opt/hadoop/pids

# watch -n.5 "jps -v | grep -vi jps"
  --> jps  자바 프로세스

[hadoop@hadoop-master /etc/profile.d](48)# sudo mv hadoop2.sh .hadoop2.sh
[hadoop@hadoop-master /etc/profile.d](49)# ssh hadoop-secmaster -C "sudo mv /etc/profile.d/hadoop2.sh /etc/profile.d/.hadoop2.sh"
[hadoop@hadoop-master /etc/profile.d](50)# ssh hadoop-worker01 -C "sudo mv /etc/profile.d/hadoop2.sh /etc/profile.d/.hadoop2.sh"
[hadoop@hadoop-master /etc/profile.d](51)# ssh hadoop-worker02 -C "sudo mv /etc/profile.d/hadoop2.sh /etc/profile.d/.hadoop2.sh"
[hadoop@hadoop-master /etc/profile.d](52)# ssh hadoop-worker03 -C "sudo mv /etc/profile.d/hadoop2.sh /etc/profile.d/.hadoop2.sh"


# start-dfs.sh

# hadoop 
Warning: $HADOOP_HOME is deprecated.
Usage: hadoop [--config confdir] COMMAND
where COMMAND is one of:
  namenode -format     format the DFS filesystem
  secondarynamenode    run the DFS secondary namenode
  namenode             run the DFS namenode
  datanode             run a DFS datanode
  dfsadmin             run a DFS admin client
  mradmin              run a Map-Reduce admin client
  fsck                 run a DFS filesystem checking utility
  fs                   run a generic filesystem user client
  balancer             run a cluster balancing utility
  oiv                  apply the offline fsimage viewer to an fsimage
  fetchdt              fetch a delegation token from the NameNode
  jobtracker           run the MapReduce job Tracker node
  pipes                run a Pipes job
  tasktracker          run a MapReduce task Tracker node
  historyserver        run job history servers as a standalone daemon
  job                  manipulate MapReduce jobs
  queue                get information regarding JobQueues
  version              print the version
  jar <jar>            run a jar file
  distcp <srcurl> <desturl> copy file or directories recursively
  distcp2 <srcurl> <desturl> DistCp version 2
  archive -archiveName NAME -p <parent path> <src>* <dest> create a hadoop archive
  classpath            prints the class path needed to get the
                       Hadoop jar and the required libraries
  daemonlog            get/set the log level for each daemon
 or
  CLASSNAME            run the class named CLASSNAME
Most commands print help when invoked w/o parameters.
  --> hadoop 에 관한 명령어가 나온다

# hadoop fs
Warning: $HADOOP_HOME is deprecated.

Usage: java FsShell
           [-ls <path>]
           [-lsr <path>]
           [-du <path>]
           [-dus <path>]
           [-count[-q] <path>]
           [-mv <src> <dst>]
           [-cp <src> <dst>]
           [-rm [-skipTrash] <path>]
           [-rmr [-skipTrash] <path>]
           [-expunge]
           [-put <localsrc> ... <dst>]
           [-copyFromLocal <localsrc> ... <dst>]
           [-moveFromLocal <localsrc> ... <dst>]
           [-get [-ignoreCrc] [-crc] <src> <localdst>]
           [-getmerge <src> <localdst> [addnl]]
           [-cat <src>]
           [-text <src>]
           [-copyToLocal [-ignoreCrc] [-crc] <src> <localdst>]
           [-moveToLocal [-crc] <src> <localdst>]
           [-mkdir <path>]
           [-setrep [-R] [-w] <rep> <path/file>]
           [-touchz <path>]
           [-test -[ezd] <path>]
           [-stat [format] <path>]
           [-tail [-f] <file>]
           [-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
           [-chown [-R] [OWNER][:[GROUP]] PATH...]
           [-chgrp [-R] GROUP PATH...]
           [-help [cmd]]

Generic options supported are
-conf <configuration file>     specify an application configuration file
-D <property=value>            use value for given property
-fs <local|namenode:port>      specify a namenode
-jt <local|jobtracker:port>    specify a job tracker
-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

The general command line syntax is
bin/hadoop command [genericOptions] [commandOptions]

  --> 하둡분산 파일 시스템의 명령어가 나온다

[hadoop@hadoop-master /opt](16)# hadoop fs -ls /
[hadoop@hadoop-master ~](18)# hadoop fs -put test.doc /test1.doc
[hadoop@hadoop-master ~](22)# hadoop fs -lsr /
Warning: $HADOOP_HOME is deprecated.

drwxr-xr-x   - hadoop supergroup          0 2017-11-11 22:09 /hadoop
drwxr-xr-x   - hadoop supergroup          0 2017-11-12 14:41 /hadoop/mapred
drwx------   - hadoop supergroup          0 2017-11-12 14:41 /hadoop/mapred/system
-rw-------   2 hadoop supergroup          4 2017-11-12 14:41 /hadoop/mapred/system/jobtracker.info
drwxr-xr-x   - hadoop supergroup          0 2017-11-13 16:34 /system
-rw-r--r--   2 hadoop supergroup          6 2017-11-13 16:41 /test1.doc


[hadoop@hadoop-master ~](23)# hadoop fs -cp /test1.doc /test2.doc
Warning: $HADOOP_HOME is deprecated.

[hadoop@hadoop-master ~](24)# hadoop fs -lsr /
Warning: $HADOOP_HOME is deprecated.

drwxr-xr-x   - hadoop supergroup          0 2017-11-11 22:09 /hadoop
drwxr-xr-x   - hadoop supergroup          0 2017-11-12 14:41 /hadoop/mapred
drwx------   - hadoop supergroup          0 2017-11-12 14:41 /hadoop/mapred/system
-rw-------   2 hadoop supergroup          4 2017-11-12 14:41 /hadoop/mapred/system/jobtracker.info
drwxr-xr-x   - hadoop supergroup          0 2017-11-13 16:34 /system
-rw-r--r--   2 hadoop supergroup          6 2017-11-13 16:41 /test1.doc
-rw-r--r--   2 hadoop supergroup          6 2017-11-13 16:42 /test2.doc

[hadoop@hadoop-master ~](25)# hadoop fs -cat /test1.doc
Warning: $HADOOP_HOME is deprecated.

hello

[hadoop@hadoop-master ~](26)# hadoop fs -text /test2.doc
Warning: $HADOOP_HOME is deprecated.

hello

  ---> cat 이나 text 로 파일을 볼수있다.

[hadoop@hadoop-master ~](29)# hadoop fs -rm /test2.doc
Warning: $HADOOP_HOME is deprecated.

Deleted hdfs://hadoop-master:9000/test2.doc


[hadoop@hadoop-master ~](33)# hadoop fs -mv /test1.doc /test2.doc
Warning: $HADOOP_HOME is deprecated.

[hadoop@hadoop-master ~](34)# hadoop fs -lsr /
Warning: $HADOOP_HOME is deprecated.

drwxr-xr-x   - hadoop supergroup          0 2017-11-11 22:09 /hadoop
drwxr-xr-x   - hadoop supergroup          0 2017-11-12 14:41 /hadoop/mapred
drwx------   - hadoop supergroup          0 2017-11-12 14:41 /hadoop/mapred/system
-rw-------   2 hadoop supergroup          4 2017-11-12 14:41 /hadoop/mapred/system/jobtracker.info
drwxr-xr-x   - hadoop supergroup          0 2017-11-13 16:34 /system
-rw-r--r--   2 hadoop supergroup          6 2017-11-13 16:41 /test2.doc


[hadoop@hadoop-master ~](35)# hadoop fs -mkdir /user
Warning: $HADOOP_HOME is deprecated.


[hadoop@hadoop-master ~](36)# hadoop fs -lsr /
Warning: $HADOOP_HOME is deprecated.

drwxr-xr-x   - hadoop supergroup          0 2017-11-11 22:09 /hadoop
drwxr-xr-x   - hadoop supergroup          0 2017-11-12 14:41 /hadoop/mapred
drwx------   - hadoop supergroup          0 2017-11-12 14:41 /hadoop/mapred/system
-rw-------   2 hadoop supergroup          4 2017-11-12 14:41 /hadoop/mapred/system/jobtracker.info
drwxr-xr-x   - hadoop supergroup          0 2017-11-13 16:34 /system
-rw-r--r--   2 hadoop supergroup          6 2017-11-13 16:41 /test2.doc
drwxr-xr-x   - hadoop supergroup          0 2017-11-13 16:46 /user


[hadoop@hadoop-master ~](38)# hadoop fs -get /test2.doc .  
    -->> 마지막에 . 을 하면 로컬에 복사된다.
Warning: $HADOOP_HOME is deprecated.

[hadoop@hadoop-master ~](39)# ll
total 8
-rw-rw-r--. 1 hadoop hadoop 6 Nov 13 17:06 test2.doc
-rw-rw-r--. 1 hadoop hadoop 6 Nov 12 14:01 test.doc


[hadoop@hadoop-master ~](46)# hadoop dfsadmin
Warning: $HADOOP_HOME is deprecated.

Usage: java DFSAdmin
           [-report]
           [-safemode enter | leave | get | wait]
           [-saveNamespace]
           [-refreshNodes]
           [-finalizeUpgrade]
           [-upgradeProgress status | details | force]
           [-metasave filename]
           [-refreshServiceAcl]
           [-refreshUserToGroupsMappings]
           [-refreshSuperUserGroupsConfiguration]
           [-setQuota <quota> <dirname>...<dirname>]
           [-clrQuota <dirname>...<dirname>]
           [-setSpaceQuota <quota> <dirname>...<dirname>]
           [-clrSpaceQuota <dirname>...<dirname>]
           [-setBalancerBandwidth <bandwidth in bytes per second>]
           [-help [cmd]]

Generic options supported are
-conf <configuration file>     specify an application configuration file
-D <property=value>            use value for given property
-fs <local|namenode:port>      specify a namenode
-jt <local|jobtracker:port>    specify a job tracker
-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

The general command line syntax is
bin/hadoop command [genericOptions] [commandOptions]



[hadoop@hadoop-master ~](40)# hadoop dfsadmin -safemode get
Warning: $HADOOP_HOME is deprecated.

Safe mode is OFF
[hadoop@hadoop-master ~](41)# hadoop dfsadmin -safemode enter
Warning: $HADOOP_HOME is deprecated.

Safe mode is ON
[hadoop@hadoop-master ~](42)# hadoop dfsadmin -safemode leave
Warning: $HADOOP_HOME is deprecated.

Safe mode is OFF
[hadoop@hadoop-master ~](43)# hadoop dfsadmin -safemode wait
Warning: $HADOOP_HOME is deprecated.

Safe mode is OFF
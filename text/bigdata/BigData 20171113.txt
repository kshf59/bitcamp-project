빅데이터


반정형(semi-structured) 데이터

1. 특징
정형데이터 : 데이터 스키마 정보관리(RDBMS) + 데이터 내용 저장소(DB)로 구분
데이터 내부에 , 정형 데이터의 스키마에 해당하는 메타데이터를 가짐
일반적으로 파일 형태로 저장

2. 탐색

데이터내부에 , 데이터 구조에 대한 메타데이터 를 가짐어떤 형태를 가진 데이터 인지를 파악하는것이 필요
데이터 내부의 규칙성을 파악 >>>> 데이터 파싱(pasing) 규칙 적용

3. 예

HTML,XML,JSON
Web Log
LOT Sensor's sensing data

--------------------------------------------------------------------------------------------------------------------------------

비정형(unstructured) 데이터

1. 특징

데이터 셋(dataset)이 아닌, 하나의 데이터가 수집 데이터로 객체화
대표적인 데이터
  - 언어분석 가능한 텍스트 데이터
  - 이미지, 동영상같은 멀티미디어 데이터
웹 페이지의 경우
  - HTML 형태로 존재 >> 반정형 데이터로 구분할 수 도 있음
  - 텍스트 마이닝을 통해 수집하는 경우도 존재 >> 명확한 구분이 어려움

2. 탐색

이진파일형태 : 동영상 이미지
스크립트(script) 파일 형태 : 소셜 데이터의 텍스트
이진 파일 형태의 데이터인 경우 >> 데이터 종류별로 응용 sw를 이용하여 탐색
스크립트 형태의 데이터인 경우 >> 데이터를 파싱해 처리

--------------------------------------------------------------------------------------------------------------------------------

데이터 수집-분류

수집데이터의 형태와 데이터 수집과의 관계

데이터 수집이 가능할 경우, 아래 세가지 측면으로 비교하면,

1. 수집의 난이도
데이터 난이도 특징
정형   하    대부분 내부 데이터, 수집 쉬움
반정형 중    보통 API 형태로 제공, 데이터 처리기술 요구
비정형 상    텍스트 마이닝, 파일의 경우는 파싱 필요 >> 처리 어려움

2. 데이터 처리 아키텍처 구성

데이터 처리 아키텍처 구성
데이터 난이도 특징
정형   하    보통,CRUD 아키텍처 구조
반정형 중    메타데이터 구조 해석 >>> 정형 데이터로 변환 아키텍처 구성
비정형 상    텍스트 or 파일 파싱 >> 반정형 >> 정형 변환 아키텍처 구성

3. 데이터의 잠재적가치
데이터 난이도   특징
정형   보통     내부 데이터 특성상, 현실적 가치 한계상, 상대적 
반정형 높음     제공자가 선별해 제공 >>> 정형 데이터보다 높음
비정형 매우높음 목적론적 데이터, 수집 주체에게 가장 높은 잠재 가치

--------------------------------------------------------------------------------------------------------------------------------

○ 수집데이터의 위치에 따른 분류

- 배치 처리시, 데이터 위치에 따른 구분
  1. 내부 데이터 :  동일한 내부의 시스템계에 저장되는 데이터
  2. 외부 데이터 : 외부 시스템에 저장된 데이터

- 실시간 처리에서는,
  수집데이터가 저장되는 위치가 아니라
  수집 데이터가 발생하는 위치에 따라 내부, 외부로 구분

- 내부/외부 구분 사유
  데이터의 위치에 따른, 원천 시스템과 연계를 위한
    1. 인터페이스의 기술적 방법과
    2. 정책적 차이점

내부 데이터

1. 특징
  - 수집 대상, 원천 데이터의 저장소가 내부 시스템계에 있는 데이터
  - 내/외부 데이터의 가장 큰 구분별점 >> 
    데이터 제공자와 상호 협약에 의한  의사소통의 가능여부
  - 상대적으로 적은 기술적제약 >> 원천/수집 데이터가 동일 시스템계에 저장

2. 인터페이스 방법
  - 대상데이터의 수집주기와 방법 >> 데이터 제공자와의 협약을 통해 결정
  - 수집실패 데이터의 재수집이 가능하도록 구현 가능 >> 수집성공여부에 따른 별도의 인터페이스 설정

외부 데이터

1. 특징
  - 수집대상 원천 데이터 저장소가 외부 시스템에 있는 데이터 
  - 내부 데이터와의 가장 큰 구별점 >> 데이터 제공자와 협약 된 관계가 아니면, 상호 의사소통 불가능
  - 데이터 수집위한, 수집주기 및 방법에 관한 분석 필요

2.인터페이스 방법
  - 수집항목을 분석해, 수집 시스템 설계
  - 미 협약 시스템의 경우, 수집 실패 시 대안 준비해야 함
  - 가능 한 데이터 전처리 과정 없이 원본 데이터 수집후, 수집 시스템에서 처리가능한 인터페이스 설계가 바람직함

--------------------------------------------------------------------------------------------------------------------------------

수집 데이터의 위치와 데이터 수집의 관계
수집 데이터의 위치와 데이터 수집과의 관계를, 아래 세가지 측면에서 분석

1. 수집 난이도
위치 난이도  특징
내부 하     데이터 저장소가 내부에 있음, 의사소통 원활
외부 상     소스 데이터담당자와 의사소통 어려움

2. 데이터 처리 아키텍처
위치 난이도  특징
내부 하      대부분 정형데이터, 일반적인 CRUD 처리 아키텍처 구성 가능
외부 상      대부분 비정형/반정형 데이터, 추가적인 아키텍쳐 구성 필요

3. 데이터의 잠재적 가치
위치 난이도  특징
내부 보통    내부 데이터 특성상, 현실적 가치의ㅔ 한계상 활용측면 낮음
외부 높음    목적론적 데이터, 수집 주체에게 가장 높은 잠재 가치

--------------------------------------------------------------------------------------------------------------------------------

#  ssh hadoop-이름 -C "/opt/mvHadoop1to2.sh"   하둡 2에서 1로 바꿔줌
#  ssh hadoop-이름 -C "/opt/mvHadoop2to1.sh"   하둡 2에서 1로 바꿔줌
  -->  "/opt.mvHadoop2to1" 이런 파일안에
          rm /opt/hadoop
          ln -s /opt/hadoop-2.8.2 /opt/hadoop
       이런 명령어가 들어있다. 
# htop
  --> 프로세스 확인하는 명령어

하둡2
# env | grep HADOOP
  HADOOP_HOME=/opt/hadoop
  HADOOP_PID_DIR=/opt/hadoop/pids
  HADOOP_PREFIX=/opt/hadoop
  HADOOP_HDFS_HOME=/opt/hadoop
  HADOOP_COMMON_HOME=/opt/hadoop
  HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
  HADOOP_MAPRED_HOME=/opt/hadoop

하둡1
# env | grep HADOOP
HADOOP_HOME=/opt/hadoop
HADOOP_PID_DIR=/opt/hadoop/pids

# watch -n.5 "jps -v | grep -vi jps"
  --> jps  자바 프로세스

[hadoop@hadoop-master /etc/profile.d](48)# sudo mv hadoop2.sh .hadoop2.sh
[hadoop@hadoop-master /etc/profile.d](49)# ssh hadoop-secmaster -C "sudo mv /etc/profile.d/hadoop2.sh /etc/profile.d/.hadoop2.sh"
[hadoop@hadoop-master /etc/profile.d](50)# ssh hadoop-worker01 -C "sudo mv /etc/profile.d/hadoop2.sh /etc/profile.d/.hadoop2.sh"
[hadoop@hadoop-master /etc/profile.d](51)# ssh hadoop-worker02 -C "sudo mv /etc/profile.d/hadoop2.sh /etc/profile.d/.hadoop2.sh"
[hadoop@hadoop-master /etc/profile.d](52)# ssh hadoop-worker03 -C "sudo mv /etc/profile.d/hadoop2.sh /etc/profile.d/.hadoop2.sh"

